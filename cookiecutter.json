{
  "projectName": "DMancipate",
  "memoryRequest": "512Mi",
  "memoryLimit": "1Gi",
  "cpuRequest": "250m",
  "cpuLimit": "500m",
  "llmClientType": "langchain",
  "inferenceServiceMode": "ollama",
  "langchainProvider": "ollama",
  "inferenceModelName": "mistral:latest",
  "inferenceBaseUrl": "http://localhost:11434",
  "inferenceApiKey": "",
  "inferenceTemperature": "0.7",
  "inferenceMaxTokens": "2048",
  "systemPrompt": "You are a dungeon master running a dungeons and dragons module."
}
